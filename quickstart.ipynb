{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbotsورشة عمل ال 💻\n",
        "\n",
        " 😀صنع بواسطة: عبدالملك القويفلي\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XdXkYweB4fKe"
      },
      "id": "XdXkYweB4fKe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## تحميل المكتبات اللازمة\n",
        "Gradio للواجهات\n",
        "\n",
        "mistralai  لطلب النموذج\n"
      ],
      "metadata": {
        "id": "NNGEtyAg50vF"
      },
      "id": "NNGEtyAg50vF"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "e0eb939e-a7e6-42d9-a7ce-c61444c5dc62",
      "metadata": {
        "id": "e0eb939e-a7e6-42d9-a7ce-c61444c5dc62",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#!pip install mistralai\n",
        "#!pip install gradio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b630861-a95e-4925-8525-d9461d3627ea",
      "metadata": {
        "id": "5b630861-a95e-4925-8525-d9461d3627ea"
      },
      "source": [
        "Our API is currently available through [La Plateforme](https://console.mistral.ai/). You need to activate payments on your account to enable your API keys. After a few moments, you will be able to use our `chat` endpoint:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Mistral وضع النموذج المطلوب من\n",
        "\n",
        "##   الخاص بكAPIوضع ال   \n",
        "\n",
        "https://console.mistral.ai/api-keys/ يمكن الحصول عليه من هنا\n",
        "\n",
        " https://docs.mistral.ai/getting-started/models/models_overview/ المودلز كلها هنا\n",
        "\n"
      ],
      "metadata": {
        "id": "nBnI4U-ClTYM"
      },
      "id": "nBnI4U-ClTYM"
    },
    {
      "source": [
        "from mistralai import Mistral\n",
        "\n",
        "#   الخاص بك APIوضع ال\n",
        "api_key = \":-)\"\n",
        "model = \"mistral-large-2402\"  # يمديك تغير المودل زي ماتبي\n",
        "\n",
        "client = Mistral(api_key=api_key)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "zHUx1oep34i4"
      },
      "id": "zHUx1oep34i4",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mistral المحادثة مع"
      ],
      "metadata": {
        "id": "gClQXFFt6ahF"
      },
      "id": "gClQXFFt6ahF"
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_mistral(message, history):\n",
        "    try:\n",
        "        # بدأ تاريخ المحادثة\n",
        "        messages = []\n",
        "        for h in history:\n",
        "            messages.append({\"role\": \"user\", \"content\": h[0]})\n",
        "            messages.append({\"role\": \"assistant\", \"content\": h[1]})\n",
        "\n",
        "        # وضع الرسالة الحالية للمستخدم ومحتوى الرسالة\n",
        "        messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "        #  API call اضدافة ال\n",
        "        chat_response = client.chat.complete(\n",
        "            model=model,\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        response = chat_response.choices[0].message.content\n",
        "\n",
        "        history.append((message, response))\n",
        "\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "xTN9TByvuTNq"
      },
      "id": "xTN9TByvuTNq",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio صنع الواجهة باستخدام"
      ],
      "metadata": {
        "id": "FBV_HsRC6ylF"
      },
      "id": "FBV_HsRC6ylF"
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "iface = gr.ChatInterface(\n",
        "    fn=chat_with_mistral,\n",
        "    title=\"Mistral AI Chatbot\",\n",
        "    description=\"Chat with the Mistral AI large language model.\",\n",
        "    theme=\"glass\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "M1WtoPUl0L57"
      },
      "id": "M1WtoPUl0L57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   transformers باستخدام ال  Hugging Face عن طريقة منصة  Chatbot كيف تسوي ال"
      ],
      "metadata": {
        "id": "IWQWjPoM7oyx"
      },
      "id": "IWQWjPoM7oyx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "تحميل المكتبات اللازمة"
      ],
      "metadata": {
        "id": "bQOnw51T8CKC"
      },
      "id": "bQOnw51T8CKC"
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transformers\n",
        "#!pip install torch"
      ],
      "metadata": {
        "id": "gWSksJ8r7neV"
      },
      "id": "gWSksJ8r7neV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "# Tokenizerاختر النموذج وال\n",
        "model_name = \"facebook/opt-125m\"  # Choose a chatbot model from Hugging Face\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "zX53gNKp71AD"
      },
      "id": "zX53gNKp71AD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "# المحادثة function\n",
        "def chat_with_huggingface(user_input, history):\n",
        "    # Tokenize the user input and add to the conversation history\n",
        "    new_user_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt')\n",
        "    bot_input_ids = torch.cat([torch.LongTensor(history), new_user_input_ids], dim=-1)\n",
        "\n",
        "    # كيفية صنع الد\n",
        "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    # فك التشفير وارجاع الرد\n",
        "\n",
        "    response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "    history.extend(new_user_input_ids.tolist()[0])\n",
        "    return response, history\n",
        "\n",
        "# بدأ تاريخ المحادثة\n",
        "chat_history = []\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_PgBqEPn8NVC"
      },
      "id": "_PgBqEPn8NVC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "# مثال لكيفية الاستخدام\n",
        "user_input = \"Hello, how are you?\"\n",
        "response, chat_history = chat_with_huggingface(user_input, chat_history)\n",
        "print(f\"Chatbot: {response}\")\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "WkWt8r-x8NMs"
      },
      "id": "WkWt8r-x8NMs",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
