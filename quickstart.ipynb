{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ChatbotsÙˆØ±Ø´Ø© Ø¹Ù…Ù„ Ø§Ù„ ğŸ’»\n",
        "\n",
        " ğŸ˜€ØµÙ†Ø¹ Ø¨ÙˆØ§Ø³Ø·Ø©: Ø¹Ø¨Ø¯Ø§Ù„Ù…Ù„Ùƒ Ø§Ù„Ù‚ÙˆÙŠÙÙ„ÙŠ\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XdXkYweB4fKe"
      },
      "id": "XdXkYweB4fKe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù„Ø§Ø²Ù…Ø©\n",
        "Gradio Ù„Ù„ÙˆØ§Ø¬Ù‡Ø§Øª\n",
        "\n",
        "mistralai  Ù„Ø·Ù„Ø¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n"
      ],
      "metadata": {
        "id": "NNGEtyAg50vF"
      },
      "id": "NNGEtyAg50vF"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "e0eb939e-a7e6-42d9-a7ce-c61444c5dc62",
      "metadata": {
        "id": "e0eb939e-a7e6-42d9-a7ce-c61444c5dc62",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#!pip install mistralai\n",
        "#!pip install gradio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b630861-a95e-4925-8525-d9461d3627ea",
      "metadata": {
        "id": "5b630861-a95e-4925-8525-d9461d3627ea"
      },
      "source": [
        "Our API is currently available through [La Plateforme](https://console.mistral.ai/). You need to activate payments on your account to enable your API keys. After a few moments, you will be able to use our `chat` endpoint:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Mistral ÙˆØ¶Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†\n",
        "\n",
        "##   Ø§Ù„Ø®Ø§Øµ Ø¨ÙƒAPIÙˆØ¶Ø¹ Ø§Ù„   \n",
        "\n",
        "https://console.mistral.ai/api-keys/ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„ÙŠÙ‡ Ù…Ù† Ù‡Ù†Ø§\n",
        "\n",
        " https://docs.mistral.ai/getting-started/models/models_overview/ Ø§Ù„Ù…ÙˆØ¯Ù„Ø² ÙƒÙ„Ù‡Ø§ Ù‡Ù†Ø§\n",
        "\n"
      ],
      "metadata": {
        "id": "nBnI4U-ClTYM"
      },
      "id": "nBnI4U-ClTYM"
    },
    {
      "source": [
        "from mistralai import Mistral\n",
        "\n",
        "#   Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ APIÙˆØ¶Ø¹ Ø§Ù„\n",
        "api_key = \":-)\"\n",
        "model = \"mistral-large-2402\"  # ÙŠÙ…Ø¯ÙŠÙƒ ØªØºÙŠØ± Ø§Ù„Ù…ÙˆØ¯Ù„ Ø²ÙŠ Ù…Ø§ØªØ¨ÙŠ\n",
        "\n",
        "client = Mistral(api_key=api_key)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "zHUx1oep34i4"
      },
      "id": "zHUx1oep34i4",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mistral Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ø¹"
      ],
      "metadata": {
        "id": "gClQXFFt6ahF"
      },
      "id": "gClQXFFt6ahF"
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_mistral(message, history):\n",
        "    try:\n",
        "        # Ø¨Ø¯Ø£ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©\n",
        "        messages = []\n",
        "        for h in history:\n",
        "            messages.append({\"role\": \"user\", \"content\": h[0]})\n",
        "            messages.append({\"role\": \"assistant\", \"content\": h[1]})\n",
        "\n",
        "        # ÙˆØ¶Ø¹ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆÙ…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø³Ø§Ù„Ø©\n",
        "        messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "        #  API call Ø§Ø¶Ø¯Ø§ÙØ© Ø§Ù„\n",
        "        chat_response = client.chat.complete(\n",
        "            model=model,\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        response = chat_response.choices[0].message.content\n",
        "\n",
        "        history.append((message, response))\n",
        "\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "xTN9TByvuTNq"
      },
      "id": "xTN9TByvuTNq",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio ØµÙ†Ø¹ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…"
      ],
      "metadata": {
        "id": "FBV_HsRC6ylF"
      },
      "id": "FBV_HsRC6ylF"
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "iface = gr.ChatInterface(\n",
        "    fn=chat_with_mistral,\n",
        "    title=\"Mistral AI Chatbot\",\n",
        "    description=\"Chat with the Mistral AI large language model.\",\n",
        "    theme=\"glass\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "M1WtoPUl0L57"
      },
      "id": "M1WtoPUl0L57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#   transformers Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„  Hugging Face Ø¹Ù† Ø·Ø±ÙŠÙ‚Ø© Ù…Ù†ØµØ©  Chatbot ÙƒÙŠÙ ØªØ³ÙˆÙŠ Ø§Ù„"
      ],
      "metadata": {
        "id": "IWQWjPoM7oyx"
      },
      "id": "IWQWjPoM7oyx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù„Ø§Ø²Ù…Ø©"
      ],
      "metadata": {
        "id": "bQOnw51T8CKC"
      },
      "id": "bQOnw51T8CKC"
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transformers\n",
        "#!pip install torch"
      ],
      "metadata": {
        "id": "gWSksJ8r7neV"
      },
      "id": "gWSksJ8r7neV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "# TokenizerØ§Ø®ØªØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„\n",
        "model_name = \"facebook/opt-125m\"  # Choose a chatbot model from Hugging Face\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "zX53gNKp71AD"
      },
      "id": "zX53gNKp71AD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "# Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© function\n",
        "def chat_with_huggingface(user_input, history):\n",
        "    # Tokenize the user input and add to the conversation history\n",
        "    new_user_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt')\n",
        "    bot_input_ids = torch.cat([torch.LongTensor(history), new_user_input_ids], dim=-1)\n",
        "\n",
        "    # ÙƒÙŠÙÙŠØ© ØµÙ†Ø¹ Ø§Ù„Ø¯\n",
        "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    # ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ± ÙˆØ§Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø±Ø¯\n",
        "\n",
        "    response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "    history.extend(new_user_input_ids.tolist()[0])\n",
        "    return response, history\n",
        "\n",
        "# Ø¨Ø¯Ø£ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©\n",
        "chat_history = []\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_PgBqEPn8NVC"
      },
      "id": "_PgBqEPn8NVC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "# Ù…Ø«Ø§Ù„ Ù„ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…\n",
        "user_input = \"Hello, how are you?\"\n",
        "response, chat_history = chat_with_huggingface(user_input, chat_history)\n",
        "print(f\"Chatbot: {response}\")\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "WkWt8r-x8NMs"
      },
      "id": "WkWt8r-x8NMs",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
